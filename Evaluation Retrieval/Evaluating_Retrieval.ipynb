{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER8GSCu4Awr5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating Retrieval\n",
        "\n",
        "The Judge UI:\n",
        "\n",
        "Using FastAPI as a backend and Vue.js as a frontend, we've custom built a Judge UI for searching different asset types via semantic or keyword search. This is essentially just a bit of wiring that is making very simple REST calls to the router. Via SQLAlchemy, we've integrated FastAPI with a little backend SQLite database to store the feedback we generate by voting on results."
      ],
      "metadata": {
        "id": "aoo5H2RpAxlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%js\n",
        "var host = window.location.host;\n",
        "var url = 'http://'+host+':5007';\n",
        "element.innerHTML = '<a style=\"color:green;\" target=\"_blank\" href='+url+'>Click to open the judge UI.</a>';"
      ],
      "metadata": {
        "id": "C_P2ZGkbA7YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voting with Judge UI\n",
        "\n",
        "Now let's vote. First let's evaluate how semantic search does on this query.\n",
        "\n",
        "1. Make sure we're in Semantic Search mode.\n",
        "2. Type `H200` in the search box.\n",
        "3. Make sure only \"TechBlog Posts Summaries\" is checked in Asset Types.\n",
        "4. Vote thumbs up or down on the 10 results. This populates our SQLite database.\n",
        "\n",
        "Now let's evaluate how keyword search does on this query.\n",
        "1. Switch to Keyword Search mode.\n",
        "2. Type `*H200` in the search box. **Include the asterisk so that we get wildcard matches on the closely-related GH200.**\n",
        "3. Make sure only \"TechBlog Posts Summaries\" is checked in Asset Types.\n",
        "4. Vote thumbs up or down on the 10 results. This populates our SQLite database."
      ],
      "metadata": {
        "id": "zJeJJ7HwBDd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "sql_db_filepath = os.path.abspath(os.path.join(os.getcwd(), \"db\", \"sql_app.db\"))\n",
        "sql_db_filepath\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "def select_all_feedback() -> pd.DataFrame:\n",
        "    # Read sqlite query results into a pandas DataFrame\n",
        "    con = sqlite3.connect(sql_db_filepath)\n",
        "    df = pd.read_sql_query(\"SELECT * FROM feedback\", con)\n",
        "    con.close()\n",
        "    return df\n",
        "\n",
        "df = select_all_feedback()\n",
        "\n",
        "# Verify that result of SQL query is stored in the dataframe\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "id": "BR-JKn2BBJbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision and Recall\n",
        "\n",
        "As in most data science evaluation tasks, we are interested in precision and recall. Remembering the definitions of each:\n",
        "\n",
        "- **Precision:** Total number of *relevant* documents retrieved / Total number of documents retrieved.\n",
        "- **Recall:** Total number of relevant documents *retrieved* / Total number of relevant documents *in the database*.\n",
        "\n",
        "In retrievers, those scores are typically calculated with the system set for some arbitrary number of results K\n",
        "\n",
        "You may see variations on these like Mean Average Precision, F1 score, or other rank-based metrics like Mean Reciprocal Rank (MRR) or Normalized Cumulative Discounted Gain (NCDG). We'll just focus on Precision and Recall in this course.\n"
      ],
      "metadata": {
        "id": "i38btcVHBPrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first filter to all the feedback we put in manually (a.k.a. human feedback)\n",
        "hf = df[df['username'] != 'llmjudge']\n",
        "\n",
        "# Next transform query column so that it strips wildcards and lowercases everything\n",
        "hf[\"query\"] = hf[\"query\"].str.replace(\"*\", \"\").str.lower()\n",
        "\n",
        "print(hf.shape)\n",
        "print(hf.head())\n",
        "\n",
        "result = hf.groupby([\"query\", \"search_type\", \"asset_type\"]).aggregate(precision=(\"vote_value\", \"mean\")).reset_index(drop=False)\n",
        "print(result)\n",
        "\n",
        "# Calculating Recall\n",
        "\n",
        "totalpos = hf[hf[\"vote_value\"] == 1].groupby(\"query\").aggregate(totalpos=(\"chunk_id\", \"nunique\")).reset_index(drop=False)\n",
        "totalpos\n",
        "\n",
        "hf = pd.merge(hf, totalpos, on=[\"query\"])\n",
        "hf_grouped = hf.groupby([\"query\", \"search_type\", \"asset_type\"]).aggregate(precision=(\"vote_value\", \"mean\"), recall=(\"vote_value\", \"sum\"), totalpos=(\"totalpos\", \"first\")).reset_index(drop=False)\n",
        "hf_grouped[\"recall\"] = hf_grouped[\"recall\"] / hf_grouped[\"totalpos\"]\n",
        "hf_grouped"
      ],
      "metadata": {
        "id": "G2znev0hBYjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM as a judge\n",
        "\n",
        "Getting human feedback is pretty important for evaluation. However, unless you have access to an automated way of continually collecting user preferences - as search engines track whether or not a user clicked on a search result - it will require a lot of dedicated person-hours to build up your database of feedback, especially as your database of document chunks scales.\n",
        "\n",
        "This leads to a natural follow-up question: can we ask a machine to evaluate whether a document is relevant or not? If so, we could solve the problem by just throwing compute at it.\n",
        "\n",
        "We are actually getting close to another important topic in information retrieval systems: **rerankers**."
      ],
      "metadata": {
        "id": "qDFv7jMhBkXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# load the summaries from the json file\n",
        "with open(\"data/techblogs_summaries/saved.json\", \"r\") as f:\n",
        "    saved_summaries = json.load(f)\n",
        "\n",
        "summary = saved_summaries['https://developer.nvidia.com/blog/create-share-and-scale-enterprise-ai-workflows-with-nvidia-ai-workbench-now-in-beta/'][0]['text']\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "lVgADfv-Bi3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use LLMs to check reference\n",
        "\n",
        "from llms import llms\n",
        "llm = llms.nim_mixtral_llm\n",
        "\n",
        "import asyncio\n",
        "\n",
        "# Initialize a semaphore object with a limit of 3.\n",
        "limit = asyncio.Semaphore(3)\n",
        "\n",
        "async def async_generate(llm, msg):\n",
        "    resp = await llm.agenerate([msg])\n",
        "    return resp.generations[0][0].text"
      ],
      "metadata": {
        "id": "94gVHm2dBu7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful AI bot being used by NVIDIA to determine if a passage of text is relevant to a search query. \"\n",
        "            + \"All of the passages of text are in some way related to NVIDIA, so in order to be relevant it needs to be a strict match between the topic of the passage and the topic of the query. \"\n",
        "            + 'Format your output as a JSON object with a single boolean field \"relevant\". ',\n",
        "        ),\n",
        "        (\n",
        "            \"user\",\n",
        "            'Is the following passage strictly relevant to a search query for \"{query}\"?\\nPassage: {passage}',\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "aN_SSPTBB2el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_messages = []\n",
        "\n",
        "# truncating the list to limit to a subset of urls\n",
        "# this example is just to illustrate the point\n",
        "# the first 5 urls should be irrelevant to H200, the next 2 should be relevant\n",
        "urls = list(saved_summaries.keys())[0:5] + ['https://developer.nvidia.com/blog/one-giant-superchip-for-llms-recommenders-and-gnns-introducing-nvidia-gh200-nvl32/', 'https://developer.nvidia.com/blog/nvidia-tensorrt-llm-enhancements-deliver-massive-large-language-model-speedups-on-nvidia-h200/']\n",
        "\n",
        "for url in urls:\n",
        "    title = saved_summaries[url][0]['document_title']\n",
        "    summary = saved_summaries[url][0]['text']\n",
        "    print(title)\n",
        "    print(summary)\n",
        "    print(\"-----\")\n",
        "    passage = title + \"\\n\" + summary\n",
        "    messages = template.format_messages(query=\"H200\", passage=passage)\n",
        "    batch_messages.append(messages)\n"
      ],
      "metadata": {
        "id": "qSRUJOAxB2fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.generate(batch_messages)\n",
        "for gen in response.generations:\n",
        "    print(gen[0].text)"
      ],
      "metadata": {
        "id": "riKZU0yGB5vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "def extract_json(text):\n",
        "    stack = []\n",
        "    start_index = None\n",
        "\n",
        "    for i, char in enumerate(text):\n",
        "        if char == '{':\n",
        "            if not stack:\n",
        "                start_index = i\n",
        "            stack.append(char)\n",
        "        elif char == '}':\n",
        "            if stack:\n",
        "                stack.pop()\n",
        "                if not stack:\n",
        "                    end_index = i + 1\n",
        "                    json_str = text[start_index:end_index]\n",
        "                    try:\n",
        "                        json_obj = json.loads(json_str)\n",
        "                        return json_obj\n",
        "                    except json.JSONDecodeError:\n",
        "                        print(\"Error: JSON decoding failed.\")\n",
        "                        return None\n",
        "            else:\n",
        "                print(\"Error: Unmatched '}' character.\")\n",
        "                return None\n",
        "\n",
        "    print(\"No JSON object found in the text.\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "vP4igC5iCPTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful AI bot being used in a technical domain. Format your output as a JSON object.\"\n",
        "human_msg_pt = HumanMessagePromptTemplate.from_template(\n",
        "    'First, is the following text a user question that needs answering or just a topic to learn more about? Second, if the text is a user question that needs answering, is the question asking for code to be written?\\nText: {text}'\n",
        ")\n",
        "# three classification categories\n",
        "code_question = AIMessage(content=\"{\\n  \\\"is_user_question\\\": true,\\n  \\\"asks_for_code\\\": true\\n}\")\n",
        "regular_question = AIMessage(content=\"{\\n  \\\"is_user_question\\\": true,\\n  \\\"asks_for_code\\\": false\\n}\")\n",
        "not_question = AIMessage(content=\"{\\n  \\\"is_user_question\\\": false\\n}\")\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessage(content=system_message),\n",
        "        human_msg_pt.format(text=\"how do I install cuda drivers\"),\n",
        "        code_question,\n",
        "        human_msg_pt.format(text=\"what is the right NVIDIA SDK to use for computer vision\"),\n",
        "        regular_question,\n",
        "        human_msg_pt.format(text=\"recommender systems for online shopping\"),\n",
        "        not_question,\n",
        "        human_msg_pt.format(text=\"How to import rapids cudf in python?\"),\n",
        "        code_question,\n",
        "        human_msg_pt.format(text=\"Generate code to make a Python web server.\"),\n",
        "        code_question,\n",
        "        human_msg_pt.format(text=\"biomedical devices\"),\n",
        "        not_question,\n",
        "        human_msg_pt.format(text=\"write some code that prints hello world\"),\n",
        "        code_question,\n",
        "        human_msg_pt.format(text=\"The leading cause of death in the 16th century was infection.\"),\n",
        "        not_question,\n",
        "        human_msg_pt.format(text=\"NVIDIA Merlin SDK for recommendation systems\"),\n",
        "        not_question,\n",
        "        human_msg_pt.format(text=\"who founded the company NVIDIA?\"),\n",
        "        regular_question,\n",
        "        human_msg_pt,\n",
        "    ]\n",
        ")\n",
        "chain = prompt | llm\n",
        "\n",
        "generation = chain.invoke({\"text\": \"what libraries should I learn in C++\"})\n",
        "print(extract_json(generation.content))"
      ],
      "metadata": {
        "id": "zFGYAYDCCSK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation = chain.invoke({\"text\": \"What is a major seventh chord?\"})\n",
        "print(extract_json(generation.content))"
      ],
      "metadata": {
        "id": "5HfAcHgcCT6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation = chain.invoke({\"text\": \"omniverse scene lighting\"})\n",
        "print(extract_json(generation.content))"
      ],
      "metadata": {
        "id": "UGfM2u6ACZc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation = chain.invoke({\"text\": \"Generate code to write a simple Python web app.\"})\n",
        "print(extract_json(generation.content))"
      ],
      "metadata": {
        "id": "I0E3Vgy0CbX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation = chain.invoke({\"text\": \"Deep learning techniques for obstacle avoidance in autonomous mobile robots\"})\n",
        "print(extract_json(generation.content))"
      ],
      "metadata": {
        "id": "L9rWveDMCWdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Web App\n",
        "\n",
        "%%js\n",
        "var host = window.location.host;\n",
        "var url = 'http://'+host+':5000';\n",
        "element.innerHTML = '<a style=\"color:green;\" target=\"_blank\" href='+url+'>Click to open the final product web app.</a>';"
      ],
      "metadata": {
        "id": "ZgsDmDKFCeKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}